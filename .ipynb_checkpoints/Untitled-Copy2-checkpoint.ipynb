{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8c60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # keywords are highlighted in green, other strings in red, etc.\n",
    "import numpy as np\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd41b020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11701, 101)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1 = pd.read_csv('fifa21_train.csv')\n",
    "file_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b150cad",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc622442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(df): \n",
    "    \n",
    "    lst = ['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF',\n",
    "       'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM',\n",
    "       'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', 'GK']\n",
    "    \n",
    "    for i in lst:\n",
    "        df[[i, i + '_pot']] = df[i].str.split('+', expand=True)\n",
    "        df[i + '_pot'] = df[i + '_pot'].astype('int') + df[i].astype('int')\n",
    "        df[i + '_pot'] = df[i + '_pot'].astype('int')\n",
    "        df[i] = df[i].astype('int')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(categoricals):\n",
    "    specialchars = ['€','★',\"lbs\"]\n",
    "    for char in specialchars:\n",
    "        for column in categoricals:\n",
    "            categoricals[column] = categoricals[column].replace(specialchars,'', regex=True)\n",
    "    \n",
    "    return categoricals #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3190025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_cm(categoricals):\n",
    "    H_feet = categoricals['Height'].str.split(\"'\").str[0]\n",
    "    H_inch = categoricals['Height'].str.split(\"'\").str[1].str.split(\"\\\"\").str[0]\n",
    "    categoricals['Height'] = (H_feet.astype(float) * 12) + H_inch.astype(float)\n",
    "    return categoricals #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88f85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_M_multiply(categoricals):\n",
    "    categoricals['Release_Clause'] = categoricals['Release_Clause'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Wage'] = categoricals['Wage'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Value'] = categoricals['Value'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Hits'] = categoricals['Hits'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    return categoricals #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f090f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_num(categoricals):\n",
    "    col_to_numercic = ['Weight', 'Value', 'Wage', 'Release_Clause', 'W/F', 'SM', 'IR', 'Hits']\n",
    "    for i in range(len(col_to_numercic)):\n",
    "        categoricals[col_to_numercic[i]] =  pd.to_numeric(categoricals[col_to_numercic[i]])\n",
    "    return categoricals #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08cfefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58+1\n",
       "1    77+0\n",
       "2    73+2\n",
       "3    50+2\n",
       "4    56+2\n",
       "Name: LS, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_1['LS'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clear(file):\n",
    "    file.columns = list(map(lambda x: x.replace(\" \",\"_\"), file.columns))\n",
    "    file=file.drop(['Club', 'BP', 'ID', 'Name', 'Nationality', 'Joined','Contract', 'Team_&_Contract', 'Loan_Date_End', 'Position'], axis=1 )\n",
    "    file=file.dropna()\n",
    "    file = file.drop_duplicates()\n",
    "    numerical = file._get_numeric_data()\n",
    "    categoricals = file.select_dtypes(['object'])\n",
    "    categoricals = split_str(categoricals) #    \n",
    "    categoricals = remove_char(categoricals) #\n",
    "    categoricals = K_M_multiply(categoricals) #\n",
    "    categoricals = height_to_cm(categoricals) #\n",
    "    categoricals = object_to_num(categoricals) #\n",
    "\n",
    "      \n",
    "    cleaned_data = pd.concat([numerical, categoricals], axis=1)\n",
    "    cleaned_data_drop_OVA = cleaned_data.drop(['OVA'], axis=1)\n",
    "    \n",
    "    numerical = cleaned_data._get_numeric_data() #\n",
    "    categoricals = cleaned_data.select_dtypes(['object']) #\n",
    "\n",
    "    return cleaned_data, cleaned_data_drop_OVA, categoricals, numerical #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed44a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp/ipykernel_1680/2139362397.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[i + '_pot'] = df[i + '_pot'].astype('int') + df[i].astype('int')\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp/ipykernel_1680/2139362397.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[i + '_pot'] = df[i + '_pot'].astype('int')\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp/ipykernel_1680/2139362397.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[i] = df[i].astype('int')\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp/ipykernel_1680/3622996779.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categoricals[column] = categoricals[column].replace(specialchars,'', regex=True)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp/ipykernel_1680/2804637082.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  categoricals['Release_Clause'] = categoricals['Release_Clause'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n"
     ]
    }
   ],
   "source": [
    "cleaned_data, cleaned_data_drop_OVA, categoricals, numerical = data_clear(file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['LS'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c2a34",
   "metadata": {},
   "source": [
    "## Data Encoding and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0eb89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encoding(cleaned_data_drop_OVA):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    categoricals = cleaned_data_drop_OVA.select_dtypes(['object'])\n",
    "    encoder = OneHotEncoder(drop='first').fit(categoricals)\n",
    "    encoded = encoder.transform(categoricals).toarray()\n",
    "    cols = encoder.get_feature_names(input_features=categoricals.columns)\n",
    "    onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "    onehot_encoded.head()\n",
    "    print(onehot_encoded.shape)\n",
    "    \n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a85d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(cleaned_data_drop_OVA):\n",
    "    from sklearn.preprocessing import MinMaxScaler # do not use the function Normalise() - it does something entirely different\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    numerical = cleaned_data_drop_OVA._get_numeric_data()\n",
    "    transformer = MinMaxScaler().fit(numerical)\n",
    "    x_normalized = transformer.transform(numerical)\n",
    "    x_normalized=pd.DataFrame(x_normalized, columns=numerical.columns)\n",
    "    x_normalized\n",
    "    print(x_normalized.shape)\n",
    "\n",
    "    return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded_for_p=encoding(cleaned_data_drop_OVA)\n",
    "x_normalized=normalizing(cleaned_data_drop_OVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c765bb4",
   "metadata": {},
   "source": [
    "## Defining X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ea478",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numerical['OVA']\n",
    "X = numerical.drop(['OVA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = pd.concat([x_normalized, onehot_encoded_for_p], axis=1)\n",
    "X_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a20fb",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split is the way ML generates its claim to fame: \n",
    "# we build the model on a portion of the data but we then validate it in \n",
    "# another \"fresh\" portion\n",
    "# our model has no opportunity to \"cheat\": it must accurately guess the values \n",
    "# in the \"fresh\" dataset that it never saw before\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2755356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#we train/fit our model like yesterday\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But now we evaluate it in the TEST portion of the data, that we did not use for training.\n",
    "# This way we know our model is genuinely guessing our donations, not just repeating the values it has seen in the training data\n",
    "\n",
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68725091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and inspect results\n",
    "results_for_p = lm.predict(X_concat)\n",
    "\n",
    "pd.concat([file_1['OVA'],pd.Series(results_for_p)],axis=1).head()\n",
    "#dont retrain transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c71205",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14816596",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2 = pd.read_csv('fifa21_validate.csv')\n",
    "file_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data, cleaned_data_drop_OVA, categoricals, numerical = data_clear(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded_for_p = encoding(cleaned_data_drop_OVA)\n",
    "x_normalized = normalizing(cleaned_data_drop_OVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numerical['OVA']\n",
    "X = numerical.drop(['OVA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = pd.concat([x_normalized, onehot_encoded_for_p], axis=1)\n",
    "X_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9afd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and inspect results\n",
    "results_for_p = lm.predict(X_concat)\n",
    "\n",
    "pd.concat([file_2['OVA'],pd.Series(results_for_p)],axis=1).head()\n",
    "#dont retrain transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4101e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a50565",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, predictions_test)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c587c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "rmse = math.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions_test)\n",
    "r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
