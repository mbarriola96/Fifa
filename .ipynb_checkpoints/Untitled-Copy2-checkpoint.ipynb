{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0d8c60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # keywords are highlighted in green, other strings in red, etc.\n",
    "import numpy as np\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bd41b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('fifa21_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b150cad",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f804c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(categoricals):   \n",
    "    for column in categoricals:\n",
    "        if [categoricals[column].isin(['+-'])]:\n",
    "            categoricals[column] = categoricals[column].str.split('+').str[0]\n",
    "        elif [(categoricals[column].isin(['-']))]:\n",
    "            categoricals[column] = categoricals[column].str.split('-').str[0]\n",
    "        else: \n",
    "            categoricals[column] = categoricals[column].str.split('+').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "713d309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(categoricals):\n",
    "    specialchars = ['€','★',\"lbs\"]\n",
    "    for char in specialchars:\n",
    "        for column in categoricals:\n",
    "            categoricals[column] = categoricals[column].replace(specialchars,'', regex=True)\n",
    "    return categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e3190025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_cm(categoricals):\n",
    "    H_feet = categoricals['Height'].str.split(\"'\").str[0]\n",
    "    H_inch = categoricals['Height'].str.split(\"'\").str[1].str.split(\"\\\"\").str[0]\n",
    "    categoricals['Height'] = (H_feet.astype(float) * 12) + H_inch.astype(float)\n",
    "    return categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c88f85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_M_multiply(categoricals):\n",
    "    categoricals['Release_Clause'] = categoricals['Release_Clause'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Wage'] = categoricals['Wage'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Value'] = categoricals['Value'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "    categoricals['Hits'] = categoricals['Hits'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f090f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_num(categoricals):\n",
    "    col_to_numercic = ['Weight', 'Value', 'Wage', 'Release_Clause', 'W/F', 'SM', 'IR', 'Hits', 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', 'GK']\n",
    "    for i in range(len(col_to_numercic)):\n",
    "        categoricals[col_to_numercic[i]] =  pd.to_numeric(categoricals[col_to_numercic[i]])\n",
    "    return categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "8e05a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clear(file):\n",
    "    file.columns = list(map(lambda x: x.replace(\" \",\"_\"), file.columns))\n",
    "    file=file.drop(['Club', 'BP','ID', 'Name', 'Nationality', 'Joined','Contract', 'Team_&_Contract', 'Loan_Date_End', 'Position'], axis=1 )\n",
    "    file=file.dropna()\n",
    "    file = file.drop_duplicates()\n",
    "    numerical = file._get_numeric_data()\n",
    "    categoricals = file.select_dtypes(['object'])\n",
    "    split_str(categoricals)\n",
    "    remove_char(categoricals)\n",
    "    K_M_multiply(categoricals)\n",
    "    height_to_cm(categoricals)\n",
    "    object_to_num(categoricals)\n",
    "    cleaned_data = pd.concat([numerical, categoricals], axis=1)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed44a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data_clear(file)\n",
    "numerical_2 = cleaned_data._get_numeric_data()\n",
    "categoricals_2= cleaned_data.select_dtypes(['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c2a34",
   "metadata": {},
   "source": [
    "## Data Encoding and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0eb89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encoding(cleaned_data):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    categoricals = cleaned_data.select_dtypes(['object'])\n",
    "    encoder = OneHotEncoder().fit(categoricals)\n",
    "    encoded_for_p = encoder.transform(categoricals).toarray()\n",
    "    encoded_for_p\n",
    "    encoder.categories_\n",
    "\n",
    "    cols=[colname for row in encoder.categories_ for colname in row]\n",
    "    cols\n",
    "    onehot_encoded_for_p = pd.DataFrame(encoded_for_p,columns=cols)\n",
    "    cols_to_drop=[row[0] for row in encoder.categories_]\n",
    "    cols_to_drop\n",
    "    onehot_encoded_for_p = onehot_encoded_for_p.drop(cols_to_drop,axis=1)\n",
    "    onehot_encoded_for_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a6a85d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(cleaned_data):\n",
    "    from sklearn.preprocessing import MinMaxScaler # do not use the function Normalise() - it does something entirely different\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    numerical = cleaned_data._get_numeric_data()\n",
    "    transformer = MinMaxScaler().fit(numerical)\n",
    "    x_normalized = transformer.transform(numerical)\n",
    "    print(numerical_normalized.shape)\n",
    "    x_normalized=pd.DataFrame(x_normalized, columns=X.columns)\n",
    "    x_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c765bb4",
   "metadata": {},
   "source": [
    "## Defining X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f08ea478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Right</th>\n",
       "      <th>Low</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Low</th>\n",
       "      <th>Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11419</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11420</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11421</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11422 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Right  Low  Medium  Low  Medium\n",
       "0        1.0  0.0     0.0  0.0     1.0\n",
       "1        1.0  0.0     0.0  1.0     0.0\n",
       "2        1.0  0.0     0.0  0.0     1.0\n",
       "3        1.0  0.0     1.0  0.0     1.0\n",
       "4        1.0  1.0     0.0  0.0     1.0\n",
       "...      ...  ...     ...  ...     ...\n",
       "11417    1.0  0.0     0.0  1.0     0.0\n",
       "11418    0.0  0.0     1.0  0.0     1.0\n",
       "11419    1.0  0.0     1.0  0.0     1.0\n",
       "11420    1.0  0.0     0.0  0.0     1.0\n",
       "11421    0.0  0.0     0.0  1.0     0.0\n",
       "\n",
       "[11422 rows x 5 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = numerical_2['OVA']\n",
    "X = numerical_2.drop(['OVA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "51102d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11422, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Growth</th>\n",
       "      <th>Attacking</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Finishing</th>\n",
       "      <th>Heading_Accuracy</th>\n",
       "      <th>Short_Passing</th>\n",
       "      <th>Volleys</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Dribbling</th>\n",
       "      <th>...</th>\n",
       "      <th>LDM</th>\n",
       "      <th>CDM</th>\n",
       "      <th>RDM</th>\n",
       "      <th>RWB</th>\n",
       "      <th>LB</th>\n",
       "      <th>LCB</th>\n",
       "      <th>CB</th>\n",
       "      <th>RCB</th>\n",
       "      <th>RB</th>\n",
       "      <th>GK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.569087</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.075949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817722</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.777518</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.113924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744304</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.892272</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.423913</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.505855</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.063291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.524051</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.555035</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.075949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11417</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.562061</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.126582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11418</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.460759</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.480094</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.088608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11419</th>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.106329</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11420</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.617722</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.580796</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.101266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11421</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.625316</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.075949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11422 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    Growth  Attacking  Crossing  Finishing  Heading_Accuracy  \\\n",
       "0      0.370370  0.038462   0.546835  0.545455   0.478261          0.431818   \n",
       "1      0.518519  0.000000   0.817722  0.681818   0.826087          0.806818   \n",
       "2      0.629630  0.000000   0.744304  0.761364   0.793478          0.329545   \n",
       "3      0.222222  0.500000   0.506329  0.431818   0.423913          0.602273   \n",
       "4      0.259259  0.307692   0.524051  0.488636   0.369565          0.636364   \n",
       "...         ...       ...        ...       ...        ...               ...   \n",
       "11417  0.481481  0.000000   0.627848  0.340909   0.750000          0.681818   \n",
       "11418  0.333333  0.192308   0.460759  0.636364   0.228261          0.522727   \n",
       "11419  0.407407  0.153846   0.106329  0.068182   0.119565          0.090909   \n",
       "11420  0.222222  0.307692   0.617722  0.659091   0.684783          0.522727   \n",
       "11421  0.222222  0.346154   0.625316  0.420455   0.663043          0.681818   \n",
       "\n",
       "       Short_Passing   Volleys     Skill  Dribbling  ...       LDM       CDM  \\\n",
       "0           0.710843  0.465116  0.569087   0.615385  ...  0.614286  0.614286   \n",
       "1           0.686747  0.837209  0.777518   0.857143  ...  0.528571  0.528571   \n",
       "2           0.807229  0.825581  0.892272   0.879121  ...  0.571429  0.571429   \n",
       "3           0.614458  0.372093  0.505855   0.538462  ...  0.600000  0.600000   \n",
       "4           0.686747  0.348837  0.555035   0.648352  ...  0.685714  0.685714   \n",
       "...              ...       ...       ...        ...  ...       ...       ...   \n",
       "11417       0.554217  0.651163  0.562061   0.626374  ...  0.414286  0.414286   \n",
       "11418       0.578313  0.279070  0.480094   0.571429  ...  0.628571  0.628571   \n",
       "11419       0.216867  0.139535  0.124122   0.131868  ...  0.142857  0.142857   \n",
       "11420       0.638554  0.430233  0.580796   0.725275  ...  0.400000  0.400000   \n",
       "11421       0.638554  0.569767  0.524590   0.648352  ...  0.385714  0.385714   \n",
       "\n",
       "            RDM       RWB        LB       LCB        CB       RCB        RB  \\\n",
       "0      0.614286  0.642857  0.637681  0.527778  0.527778  0.527778  0.637681   \n",
       "1      0.528571  0.614286  0.565217  0.444444  0.444444  0.444444  0.565217   \n",
       "2      0.571429  0.642857  0.565217  0.347222  0.347222  0.347222  0.565217   \n",
       "3      0.600000  0.600000  0.623188  0.583333  0.583333  0.583333  0.623188   \n",
       "4      0.685714  0.714286  0.710145  0.625000  0.625000  0.625000  0.710145   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11417  0.414286  0.457143  0.434783  0.375000  0.375000  0.375000  0.434783   \n",
       "11418  0.628571  0.700000  0.710145  0.625000  0.625000  0.625000  0.710145   \n",
       "11419  0.142857  0.157143  0.144928  0.138889  0.138889  0.138889  0.144928   \n",
       "11420  0.400000  0.500000  0.449275  0.263889  0.263889  0.263889  0.449275   \n",
       "11421  0.385714  0.457143  0.434783  0.277778  0.277778  0.277778  0.434783   \n",
       "\n",
       "             GK  \n",
       "0      0.075949  \n",
       "1      0.113924  \n",
       "2      0.037975  \n",
       "3      0.063291  \n",
       "4      0.075949  \n",
       "...         ...  \n",
       "11417  0.126582  \n",
       "11418  0.088608  \n",
       "11419  0.759494  \n",
       "11420  0.101266  \n",
       "11421  0.075949  \n",
       "\n",
       "[11422 rows x 87 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = pd.concat([x_normalized, onehot_encoded_for_p], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split is the way ML generates its claim to fame: \n",
    "# we build the model on a portion of the data but we then validate it in \n",
    "# another \"fresh\" portion\n",
    "# our model has no opportunity to \"cheat\": it must accurately guess the values \n",
    "# in the \"fresh\" dataset that it never saw before\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2755356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#we train/fit our model like yesterday\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But now we evaluate it in the TEST portion of the data, that we did not use for training.\n",
    "# This way we know our model is genuinely guessing our donations, not just repeating the values it has seen in the training data\n",
    "\n",
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68725091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and inspect results\n",
    "results_for_p = lm.predict(X_concat)\n",
    "\n",
    "pd.concat([file,pd.Series(results_for_p)],axis=1).head()\n",
    "#dont retrain transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c71205",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd530f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14816596",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('fifa21_validate.csv')\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fd29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.columns = list(map(lambda x: x.replace(\" \",\"_\"), file.columns))\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b59129",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file.drop(['ID', 'Name', 'Nationality', 'Joined','Contract', 'Team_&_Contract', 'Loan_Date_End', 'Position'], axis=1 )\n",
    "file=file.dropna()\n",
    "file = file.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ecf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = file._get_numeric_data()\n",
    "categoricals= file.select_dtypes(['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3abfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_char(categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals['Release_Clause'] = categoricals['Release_Clause'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "categoricals['Wage'] = categoricals['Wage'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "categoricals['Value'] = categoricals['Value'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n",
    "categoricals['Hits'] = categoricals['Hits'].replace({'€': '', 'K': '*1e3', 'M': '*1e6'}, regex=True).map(pd.eval).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_feet = categoricals['Height'].str.split(\"'\").str[0]\n",
    "H_inch = categoricals['Height'].str.split(\"'\").str[1].str.split(\"\\\"\").str[0]\n",
    "\n",
    "categoricals['Height'] = (H_feet.astype(float) * 12) + H_inch.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_numercic = ['Weight', 'Value', 'Wage', 'Release_Clause', 'W/F', 'SM', 'IR', 'Hits', 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', 'GK']\n",
    "\n",
    "for i in range(len(col_to_numercic)):\n",
    "    categoricals[col_to_numercic[i]] =  pd.to_numeric(categoricals[col_to_numercic[i]])\n",
    "#categoricals[col_to_numercic[i]] = [col_to_numercic[i]].map(pd.eval).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2 = pd.concat([numerical, categoricals], axis=1)\n",
    "numerical_2 = file_2._get_numeric_data()\n",
    "categoricals_2= file_2.select_dtypes(['object'])\n",
    "y = numerical_2['OVA']\n",
    "X = numerical_2.drop(['OVA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e616dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_2 = categoricals_2.drop(['Club', 'BP'], axis=1)\n",
    "categoricals_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder().fit(categoricals_2)\n",
    "encoded_for_p = encoder.transform(categoricals_2).toarray()\n",
    "encoded_for_p\n",
    "encoder.categories_\n",
    "\n",
    "cols=[colname for row in encoder.categories_ for colname in row]\n",
    "cols\n",
    "onehot_encoded_for_p = pd.DataFrame(encoded_for_p,columns=cols)\n",
    "cols_to_drop=[row[0] for row in encoder.categories_]\n",
    "cols_to_drop\n",
    "onehot_encoded_for_p = onehot_encoded_for_p.drop(cols_to_drop,axis=1)\n",
    "onehot_encoded_for_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # do not use the function Normalise() - it does something entirely different\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizing data: make data range from 0 - 1, instead of from min to max\n",
    "transformer = MinMaxScaler().fit(X)\n",
    "x_normalized = transformer.transform(X)\n",
    "print(x_normalized.shape)\n",
    "x_normalized=pd.DataFrame(x_normalized, columns=X.columns)\n",
    "x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = pd.concat([x_normalized, onehot_encoded_for_p], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_concat, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#we train/fit our model like yesterday\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and inspect results\n",
    "results_for_p = lm.predict(X_concat)\n",
    "\n",
    "pd.concat([file,pd.Series(results_for_p)],axis=1).head()\n",
    "#dont retrain transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7fb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39b032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
